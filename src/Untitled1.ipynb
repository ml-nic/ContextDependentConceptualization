{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify( input, training, threshold=0.0 ):\n",
    "\n",
    "    input_cols = input.keys()\n",
    "    training_cols = training.keys()\n",
    "\n",
    "    # store the results here\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    # look at each input column\n",
    "    for icol in input_cols:\n",
    "        # keep track of the similarity measure as we compare each against\n",
    "        # each training column fingerprint\n",
    "        cosines = {}\n",
    "        for tcol in training_cols:\n",
    "            cosines[tcol] = cosine_sim( input[icol], training[tcol] )\n",
    "\n",
    "        # sort the results\n",
    "        sorted_cosines = sorted( cosines.iteritems(),\n",
    "                                 key=lambda x:x[1],\n",
    "                                 reverse=True )\n",
    "\n",
    "        # keep the top result and any others above the threshold\n",
    "        for i, (candidate, score) in enumerate(sorted_cosines):\n",
    "            if (i == 0) or (score >= threshold):\n",
    "                results[icol].append( (candidate, round(score,4)) )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between the input vector & the training vector\n",
    "def cosine_sim( ivec, tvec ):\n",
    "    # dot product\n",
    "    dot = 0.0\n",
    "    for i, t in zip(ivec, tvec):\n",
    "        dot += (i*t)\n",
    "\n",
    "    # vector length\n",
    "    ilen = sqrt( sum( [i*i for i in ivec] ) )\n",
    "    tlen = sqrt( sum( [t*t for t in tvec] ) )\n",
    "\n",
    "    return dot/(ilen*tlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concept_distribution1 = 0\n",
    "concept_distribution2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence1, word1, sentence2, word2):\n",
    "    global concept_distribution1\n",
    "    global concept_distribution2\n",
    "    concept_distribution1 = conceptualizer.conceptualize(sentence1, word1, eval=True)\n",
    "    concept_distribution2 = conceptualizer.conceptualize(sentence2, word2, eval=True)\n",
    "    for concept in concept_distribution1:\n",
    "        if concept not in concept_distribution2:\n",
    "            print(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Conceptualizer import Conceptualizer\n",
    "from LDA import LDA\n",
    "\n",
    "\n",
    "MODEL_BASE_DIR = 'F:/Not_Uploaded/conceptualization_eval/models/'\n",
    "MODEL_FILE_EXTENSION = '.gensim'\n",
    "model_names = [\n",
    "    'ldamodel_50',\n",
    "    'ldamodel_topics100_trainiter20_en_noStopWords',\n",
    "    'ldamodel_topics100_trainiter20_full_en',\n",
    "    'ldamodel_topics100_trainiter20_train_en',\n",
    "    'ldamodel_topics100_trainiter20_train_en_keep_all'\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(\"\\nTest\", model_name, ':')\n",
    "    lda = LDA()\n",
    "    lda.load(MODEL_BASE_DIR + model_name + MODEL_FILE_EXTENSION)\n",
    "    conceptualizer = Conceptualizer(lda)\n",
    "    context_instances = [\n",
    "        ('. Honda produces the Insight , an affordable hybrid electric vehicle that competes with Toyota Prius Its first entrance into the pickup segment , the lightduty Ridgeline , won Truck of the Year from \" Motor Trend \" magazine in 2006 ( also in 2006 , the redesigned Civic won <b> Car </b> of the Year from the magazine , giving Honda a rare double win of Motor Trend honors ) . Mountain bikes . Honda has also built a Downhill racing bike , known as the Honda RN-01 . Honda has taken on several people to pilot the bike , among',\n",
    "         'Car',\n",
    "         \"corporate offices in Tamil Nadu . Many heavy engineering and manufacturing companies are located in and around the suburbs of Chennai ( nicknamed , ' Detroit of Asia ' ) and Coimbatore ( nicknamed ' Manchester of South India ' ) . Tamil Nadu has seen major investments in the <b> automobile </b> industry over many decades manufacturing cars , railway coaches , battle-tanks , tractors , motorcycles , automobile spare parts and accessories , tyres and heavy vehicles . Major global automobile companies including Ford , Renault-Nissan , and Hyundai have complete manufacturing operations in Tamil Nadu . The region around\",\n",
    "         'automobile')\n",
    "    ]\n",
    "    for element in context_instances:\n",
    "        evaluate(element[0], element[1], element[2], element[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vector1 = np.zeros(np.max([len(concept_distribution1), len(concept_distribution2)]))\n",
    "vector2 = np.zeros(np.max([len(concept_distribution1), len(concept_distribution2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(concept_distribution1) == np.max([len(concept_distribution1), len(concept_distribution2)]):\n",
    "    counter = 0\n",
    "    for concept1 in concept_distribution1:\n",
    "        vector1[counter] = concept1[1]\n",
    "        for concept2 in concept_distribution2:\n",
    "            if concept1[0] == concept2[0]:\n",
    "                vector2[counter] = concept2[1]\n",
    "                break\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concept_distribution1[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pearsonr([[0.71]], [[8.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_set = []\n",
    "with(open('../ratings.txt', 'r')) as file:\n",
    "    for line in file.readlines():\n",
    "        splitted_line = line.split('\\t')\n",
    "        id = splitted_line[0]\n",
    "        word1 = splitted_line[1]\n",
    "        pos_word1 = splitted_line[2]\n",
    "        word2 = splitted_line[3]\n",
    "        pos_word2 = splitted_line[4]\n",
    "        word1_in_context = splitted_line[5]\n",
    "        word2_in_context = splitted_line[6]\n",
    "        average_human_rating = splitted_line[7]\n",
    "        ten_individual_human_ratings = [rating.replace('\\n', '') for rating in splitted_line[7:len(splitted_line)]]\n",
    "        word1_in_context = word1_in_context.replace('<b> ', '').replace(' </b>','')\n",
    "        word2_in_context = word2_in_context.replace('<b> ', '').replace(' </b>','')\n",
    "        eval_set.append((id, word1, word2, word1_in_context, word2_in_context, average_human_rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.append(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([3, 3,3]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\Anaconda3\\envs\\kbqa\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from Conceptualizer import Conceptualizer\n",
    "from LDA import LDA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "MODEL_BASE_DIR = 'F:/Not_Uploaded/conceptualization_eval/models/'\n",
    "MODEL_FILE_EXTENSION = '.gensim'\n",
    "lda = LDA()\n",
    "lda.load(MODEL_BASE_DIR + 'ldamodel_50' + MODEL_FILE_EXTENSION)\n",
    "conceptualizer = Conceptualizer(lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concept application is not in corpus\n",
      "concept heavily wooded less disturbed area is not in corpus\n",
      "concept texture is not in corpus\n",
      "concept application is not in corpus\n",
      "concept heavily wooded less disturbed area is not in corpus\n",
      "concept texture is not in corpus\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"just as thrilled for Hurst and England as the other squad players who had not been picked for the final . After the match . It was n't until the celebratory banquet that evening that Hurst realised he had scored a hat-trick , assuming that the final whistle had been blown before he 'd struck the ball into the net for his third goal . This meant he had not attempted to get the match ball as a souvenir , which hat-trick scorers traditionally do . Haller , scorer of the Germans ' first goal , acquired the ball and\"\n",
    "word1 = \"blown\"\n",
    "sentence2 = \"the west beam and do so with a speed consistent with Earth 's sidereal rotation rate . A third receiver observed the horizon to veto signals of obvious terrestrial origin . On March 23 , 1999 the 26-meter radio telescope on which Sentinel , META and BETA were based was blown over by strong winds and seriously damaged . This forced the BETA project to cease operation . MOP and Project Phoenix . In 1992 , the U.S. government funded an operational SETI program , in the form of the NASA Microwave Observing Program ( MOP ) . MOP was\"\n",
    "word2 = \"blown\"\n",
    "\n",
    "concept_distribution1 = conceptualizer.conceptualize(sentence1, word1, eval=True)\n",
    "concept_distribution2 = conceptualizer.conceptualize(sentence2, word2, eval=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(concept_distribution2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:kbqa]",
   "language": "python",
   "name": "conda-env-kbqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
